# -*- coding: utf-8 -*-
"""SlashTask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mXe6P_bh-0Dod70PREsy66DpYyvjSvDt
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Step 1: Exploratory Data Analysis (EDA)

## Data-Inspection
"""

import pandas as pd
import numpy as np

# Try with 'latin1' encoding
df = pd.read_csv('/content/drive/MyDrive/SlashTask/Amazon Sale Report.csv', encoding='latin1')
df.head()

df.info()

"""## Summary Statistics"""

# Summary statistics for numerical variables
summary_statistics_numerical = df.describe()
print("Summary Statistics for Numerical Variables:")
print(summary_statistics_numerical)

# Summary statistics for categorical variables
summary_statistics_categorical = df.describe(include='object')
print("\nSummary Statistics for Categorical Variables:")
print(summary_statistics_categorical)

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize distribution of numerical columns
plt.figure(figsize=(15, 5))

# Histogram for the 'Qty' column
plt.subplot(1, 3, 1)
sns.histplot(df['Qty'], kde=True)
plt.title('Distribution of Qty')

# Histogram for the 'Amount' column
plt.subplot(1, 3, 2)
sns.histplot(df['Amount'], kde=True)
plt.title('Distribution of Amount')

# Box plot for the 'Amount' column
plt.subplot(1, 3, 3)
sns.boxplot(x=df['Amount'])
plt.title('Box Plot of Amount')

plt.tight_layout()
plt.show()

# Visualize distribution of categorical columns
plt.figure(figsize=(15, 5))

# Bar plot for the 'Status' column
plt.subplot(1, 2, 1)
sns.countplot(y=df['Status'], order=df['Status'].value_counts().index)
plt.title('Count Plot of Status')

# Bar plot for the 'Category' column
plt.subplot(1, 2, 2)
sns.countplot(y=df['Category'], order=df['Category'].value_counts().index)
plt.title('Count Plot of Category')

plt.tight_layout()
plt.show()

"""#Step 2: Data Preprocessing

## 1. Handling Missing Values:
"""

np.round((df.isna().sum()/df.shape[0])*100)

"""As fulfilled-by is 70%, promotions-ids is 38%, and unnamed:22 is 38% those exceeds 30% mark, i will drop them from the dataset."""

df.__delitem__('promotion-ids')
df.__delitem__('fulfilled-by')
df.__delitem__('Unnamed: 22')

df.isna().sum()

"""###Imputing Numerical"""

df[df['index'].isna()].head()

df[df['Qty'].isna()].head()

df[df['Amount'].isna()].head()

df[df['ship-postal-code'].isna()].head()

print(df['Qty'].median())
print(df['Amount'].median())

df = df.fillna({
    'Qty': df['Qty'].median(),
})
df = df.fillna({
    'Amount': df['Amount'].median(),
})

print(df[df['Qty'].isna()].head())
print(df[df['Amount'].isna()].head())

print(df['ship-postal-code'].mode()[0])
print(df['index'].mode()[0])

df = df.fillna({
    'ship-postal-code': df['ship-postal-code'].mode()[0],
})
df = df.fillna({
    'index': df['index'].mode()[0],
})

print(df[df['ship-postal-code'].isna()].head())
print(df[df['index'].isna()].head())

"""###Imputing Categorical"""

print(df['SKU'].mode()[0])
print(df['Category'].mode()[0])
print(df['Size'].mode()[0])
print(df['ASIN'].mode()[0])
print(df['Courier Status'].mode()[0])
print(df['currency'].mode()[0])
print(df['ship-city'].mode()[0])
print(df['ship-state'].mode()[0])
print(df['ship-country'].mode()[0])
print(df['B2B'].mode()[0])

df = df.fillna({
    'SKU': df['SKU'].mode()[0],
})
df = df.fillna({
    'Category': df['Category'].mode()[0],
})
df = df.fillna({
    'Size': df['Size'].mode()[0],
})
df = df.fillna({
    'ASIN': df['ASIN'].mode()[0],
})
df = df.fillna({
    'Courier Status': df['Courier Status'].mode()[0],
})
df = df.fillna({
    'currency': df['currency'].mode()[0],
})
df = df.fillna({
    'ship-city': df['ship-city'].mode()[0],
})
df = df.fillna({
    'ship-state': df['ship-state'].mode()[0],
})
df = df.fillna({
    'ship-country': df['ship-country'].mode()[0],
})
df = df.fillna({
    'B2B': df['B2B'].mode()[0],
})

"""After Cleaning"""

df.isna().sum()

df.duplicated().sum()

"""##2. Data Type Conversion:"""

df['index'] = df['index'].astype('int64')
df['Order ID'] = df['Order ID'].astype(str)
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
df['Status'] = df['Status'].astype('category')
df['Fulfilment'] = df['Fulfilment'].astype('category')
df['Sales Channel '] = df['Sales Channel '].astype('category')
df['ship-service-level'] = df['ship-service-level'].astype('category')
df['Style'] = df['Style'].astype('category')
df['SKU'] = df['SKU'].astype('category')
df['Category'] = df['Category'].astype('category')
df['Size'] = df['Size'].astype('category')
df['ASIN'] = df['ASIN'].astype('category')
df['Courier Status'] = df['Courier Status'].astype('category')
df['Qty'] = df['Qty'].astype('float64')
df['currency'] = df['currency'].astype('category')
df['Amount'] = df['Amount'].astype('float64')
df['ship-city'] = df['ship-city'].astype('category')
df['ship-state'] = df['ship-state'].astype('category')
df['ship-postal-code'] = df['ship-postal-code'].astype(str)
df['ship-country'] = df['ship-country'].astype('category')
df['B2B'] = df['B2B'].astype('category')



# Verify the changes
print(df.dtypes)



"""##3.Outlier Detection and Treatment:"""

def detect_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers

# Detect outliers in Qty and Amount columns
outliers_qty = detect_outliers_iqr(df, 'Qty')
outliers_amount = detect_outliers_iqr(df, 'Amount')

print("Outliers in Qty column:")
print(outliers_qty)

print("\nOutliers in Amount column:")
print(outliers_amount)

def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df

# Remove outliers in Qty and Amount columns
df_cleaned = remove_outliers_iqr(df, 'Qty')
df_cleaned = remove_outliers_iqr(df_cleaned, 'Amount')

print("Data after removing outliers:")
print(df_cleaned)



"""# Step 3: Data Visualization

##1.Using Matplotlib and Seaborn:
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the aesthetic style of the plots
sns.set_style("whitegrid")

# 1. Histograms for 'Qty' and 'Amount'
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.histplot(df_cleaned['Qty'], kde=True)
plt.title('Distribution of Qty')

plt.subplot(1, 2, 2)
sns.histplot(df_cleaned['Amount'], kde=True)
plt.title('Distribution of Amount')

plt.tight_layout()
plt.show()

# 2. Bar plots for 'Status' and 'Category'
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.countplot(y=df_cleaned['Status'], order=df_cleaned['Status'].value_counts().index)
plt.title('Count Plot of Status')

plt.subplot(1, 2, 2)
sns.countplot(y=df_cleaned['Category'], order=df_cleaned['Category'].value_counts().index)
plt.title('Count Plot of Category')

plt.tight_layout()
plt.show()

# 3. Line plot for 'Date' vs. 'Amount'
plt.figure(figsize=(12, 6))
df.sort_values('Date', inplace=True)
sns.lineplot(data=df, x='Date', y='Amount')
plt.title('Trend of Amount Over Time')
plt.xlabel('Date')
plt.ylabel('Amount')
plt.show()

# 4. Heatmap for correlations between numerical variables
plt.figure(figsize=(12, 6))
correlation_matrix = df_cleaned[['Qty', 'Amount']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Heatmap')
plt.show()

"""##2.Visual Analysis:

"""

# Ensure Date column is in datetime format
df['Date'] = pd.to_datetime(df_cleaned['Date'], errors='coerce')

# Drop rows with invalid dates
df_cleaned = df_cleaned.dropna(subset=['Date'])

# Extract month and year from the Date column
df_cleaned['Month'] = df_cleaned['Date'].dt.to_period('M')

# Group by Month and calculate total sales
monthly_sales = df_cleaned.groupby('Month')['Amount'].sum().reset_index()

# Convert 'Month' to datetime for proper plotting
monthly_sales['Month'] = monthly_sales['Month'].dt.to_timestamp()

# Plot monthly sales trends
plt.figure(figsize=(12, 6))
sns.lineplot(data=monthly_sales, x='Month', y='Amount')
plt.title('Monthly Sales Trends')
plt.xlabel('Month')
plt.ylabel('Total Sales Amount')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Aggregate sales data to identify top-selling products
top_skus_sales = df_cleaned.groupby('SKU')['Amount'].sum().reset_index()

# Get the top 10 selling products based on total sales amount
top_skus = top_skus_sales.nlargest(10, 'Amount')

# Filter the original dataframe to include only the top 10 SKUs
top_skus_data = df_cleaned[df_cleaned['SKU'].isin(top_skus['SKU'])]

# Create a boxplot for the top-selling products
plt.figure(figsize=(12, 6))
sns.boxplot(x='Amount', y='SKU', data=top_skus_data, palette='viridis')
plt.title('Boxplot of Sales Amount for Top 10 Selling Products (SKUs)')
plt.xlabel('Sales Amount')
plt.ylabel('SKU')
plt.show()



# Top-selling categories
top_categories = df_cleaned.groupby('Category')['Amount'].sum().nlargest(10).reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(data=top_categories, x='Amount', y='Category')
plt.title('Top 10 Selling Categories')
plt.xlabel('Total Sales Amount')
plt.ylabel('Category')
plt.show()

import plotly.express as px

# Aggregate sales by country
country_sales = df.groupby('ship-country')['Amount'].sum().reset_index()

# Check for sufficient variation in sales amounts
print(country_sales)

# Create a choropleth map
fig = px.choropleth(country_sales,
                    locations='ship-country',
                    locationmode='country names',
                    color='Amount',
                    hover_name='ship-country',
                    color_continuous_scale='Viridis',
                    title='Sales Distribution by Country')

fig.update_geos(showcoastlines=True, coastlinecolor="Black",
                showland=True, landcolor="white",
                showocean=True, oceancolor="lightblue",
                showlakes=True, lakecolor="lightblue",
                showrivers=True, rivercolor="lightblue")

fig.show()

df.to_csv('newAmazonData.csv', index=False)

df.head()

"""#Step-4 Predictive Modeling

##1. Building Predictive Models:
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.impute import SimpleImputer

# Dropping unnecessary columns
columns_to_drop = ['index', 'Order ID', 'Date', 'ASIN', 'Month']
df_new = df.drop(columns=[col for col in columns_to_drop if col in df.columns])


# Define the list of categorical columns
categorical_columns = [
    'Status', 'Fulfilment', 'ship-service-level',
    'Style', 'SKU', 'Category', 'Size', 'Courier Status',
    'ship-city', 'ship-state', 'ship-postal-code', 'ship-country',
    'currency', 'B2B'
]

# Create an instance of LabelEncoder
label_encoder = LabelEncoder()

# Create a new DataFrame for the encoded columns
encoded_dataframe = pd.DataFrame()

# Apply LabelEncoder to categorical columns and insert into the new DataFrame
for column in categorical_columns:
    encoded_dataframe[column] = label_encoder.fit_transform(df_new[column])

print(encoded_dataframe.head())

# Define features X and target y
X = encoded_dataframe.drop(columns=['Status'])
y = encoded_dataframe['Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)
y_pred_log_reg = log_reg.predict(X_test)

# Train Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
y_pred_decision_tree = decision_tree.predict(X_test)

# Train Random Forest
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train, y_train)
y_pred_random_forest = random_forest.predict(X_test)

# Evaluate models
log_reg_metrics = {
    "accuracy": accuracy_score(y_test, y_pred_log_reg),
    "precision": precision_score(y_test, y_pred_log_reg, average='weighted'),
    "recall": recall_score(y_test, y_pred_log_reg, average='weighted')
}

decision_tree_metrics = {
    "accuracy": accuracy_score(y_test, y_pred_decision_tree),
    "precision": precision_score(y_test, y_pred_decision_tree, average='weighted'),
    "recall": recall_score(y_test, y_pred_decision_tree, average='weighted')
}

random_forest_metrics = {
    "accuracy": accuracy_score(y_test, y_pred_random_forest),
    "precision": precision_score(y_test, y_pred_random_forest, average='weighted'),
    "recall": recall_score(y_test, y_pred_random_forest, average='weighted')
}

log_reg_metrics, decision_tree_metrics, random_forest_metrics

"""## Cross-Validation"""

from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Ensure you use stratified cross-validation
cv = StratifiedKFold(n_splits=5)

# Logistic Regression Cross-Validation with scaling and increased max_iter
log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))
log_reg_cv = cross_val_score(log_reg, X, y, cv=cv, scoring='accuracy')

# Decision Tree Cross-Validation with scaling
decision_tree = make_pipeline(StandardScaler(), DecisionTreeClassifier())
decision_tree_cv = cross_val_score(decision_tree, X, y, cv=cv, scoring='accuracy')

# Random Forest Cross-Validation with scaling
random_forest = make_pipeline(StandardScaler(), RandomForestClassifier())
random_forest_cv = cross_val_score(random_forest, X, y, cv=cv, scoring='accuracy')

log_reg_cv.mean(), decision_tree_cv.mean(), random_forest_cv.mean()

"""#Step 5: Dashboard Development

## Dashboard Design:
"""

!pip install dash pandas plotly matplotlib seaborn

import dash
import dash_core_components as dcc
import dash_html_components as html
from dash.dependencies import Input, Output
import plotly.express as px
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# Matplotlib visualization
def create_matplotlib_fig(filtered_df):
    fig, ax = plt.subplots()
    filtered_df['Amount'].hist(ax=ax, bins=20)
    ax.set_title('Distribution of Amounts')

    buffer = io.BytesIO()
    fig.savefig(buffer, format='png')
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    return img_base64

# Seaborn visualization
def create_seaborn_fig(filtered_df):
    fig, ax = plt.subplots()
    sns.countplot(data=filtered_df, x='Status', ax=ax)
    buffer = io.BytesIO()
    fig.savefig(buffer, format='png')
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    return img_base64

# Initialize Dash app
app = dash.Dash(__name__)
app.layout = html.Div([
    html.H1('Sales Dashboard'),

    # Dropdowns for interactivity
    html.Div([
        dcc.Dropdown(
            id='category-filter',
            options=[{'label': category, 'value': category} for category in df['Category'].unique()],
            value=[df['Category'].unique()[0]],
            multi=True,
            placeholder="Select Categories"
        ),
        dcc.Dropdown(
            id='status-filter',
            options=[{'label': status, 'value': status} for status in df['Status'].unique()],
            value=[df['Status'].unique()[0]],
            multi=True,
            placeholder="Select Statuses"
        )
    ], style={'width': '48%', 'display': 'inline-block'}),

    # Display Plotly visualizations
    dcc.Graph(id='sales-trend'),
    dcc.Graph(id='qty-distribution'),
    dcc.Graph(id='sales-by-country'),
    dcc.Graph(id='fulfilment-method-distribution'),
    dcc.Graph(id='sales-channel-distribution'),

    # Display Matplotlib visualization
    html.Img(id='matplotlib-img'),

    # Display Seaborn visualization
    html.Img(id='seaborn-img'),

    # Link to access the dashboard
    html.A('Access the Dashboard', href='http://127.0.0.1:8050/', target='_blank', style={'fontSize': '20px', 'marginTop': '20px', 'display': 'block'})
])

@app.callback(
    [Output('sales-trend', 'figure'),
     Output('qty-distribution', 'figure'),
     Output('sales-by-country', 'figure'),
     Output('fulfilment-method-distribution', 'figure'),
     Output('sales-channel-distribution', 'figure'),
     Output('matplotlib-img', 'src'),
     Output('seaborn-img', 'src')],
    [Input('category-filter', 'value'),
     Input('status-filter', 'value')]
)
def update_graphs(selected_categories, selected_statuses):
    filtered_df = df[df['Category'].isin(selected_categories) & df['Status'].isin(selected_statuses)]

    # Sales trend over time
    sales_trend_fig = px.line(filtered_df, x='Date', y='Amount', color='Status', title='Sales Trend Over Time')

    # Quantity distribution across categories
    qty_distribution_fig = px.histogram(filtered_df, x='Category', y='Qty', color='Category', title='Quantity Distribution Across Categories')

    # Sales by country
    sales_by_country_fig = px.bar(filtered_df, x='ship-country', y='Amount', color='ship-country', title='Sales by Country')

    # Fulfilment method distribution
    fulfilment_method_fig = px.pie(filtered_df, names='Fulfilment', title='Fulfilment Method Distribution')

    # Sales channel distribution
    sales_channel_fig = px.pie(filtered_df, names='Sales Channel', title='Sales Channel Distribution')

    # Matplotlib visualization
    matplotlib_img = 'data:image/png;base64,{}'.format(create_matplotlib_fig(filtered_df))

    # Seaborn visualization
    seaborn_img = 'data:image/png;base64,{}'.format(create_seaborn_fig(filtered_df))

    return sales_trend_fig, qty_distribution_fig, sales_by_country_fig, fulfilment_method_fig, sales_channel_fig, matplotlib_img, seaborn_img

# Run the Dash app
if __name__ == '__main__':
    app.run_server(debug=True)